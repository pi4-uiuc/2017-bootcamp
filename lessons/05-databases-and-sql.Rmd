# Spreadsheets and Tables

## Miscanthus Yields

https://docs.google.com/spreadsheets/d/1MNG5BH6oDaRH4Ii1ZO7tVRV7pTZRKPv81In1NFdLFbs/edit#gid=0

## Sorghum Data from Arizona

Lets start with a spreadsheet that was prepared by a colleague of mine, Maria Newcomb, in Arizona

https://docs.google.com/spreadsheets/d/1ESwAR2-BpQ2HfaCoSDCQaiBJVab_5sHawEltyYcLP8U/edit#gid=932079509

Let's review the pages

* README is good. They are well ahead of the curve on this!
* What additional information is here?
* Where is the data we want to look at?
* What information is redundant


* Download the table "PlantHeights_AllPlots" as CSV


# Data Cleaning 

* In this lesson, we will use Open Refine to find errors, sort, and clean our dataset. 
* Open the OpenRefine container in the NDSLabs workbench

## About Open Refine

This tutorial is based on the [Data Carpentry Open Refine for Ecology lesson](http://www.datacarpentry.org/OpenRefine-ecology-lesson/01-working-with-openrefine/), modified to use our datasets.

You can learn more about and download Open Refine at [openrefine.org](https://openrefine.org). 


## Importing Data into Open Refine

Once OpenRefine is launched in your browser, the left margin has options to Create Project, Open Project, or Import Project. Here we will create a new project:

* click 'Create Project'; 'Get data from This Computer' should be selected
   * what other ways can you get data into OpenRefine?
* Click Choose Files and select the file `DRAFT_Sorghum2_PlantHeights_AugustPlanting-training-sample - PlantHeights_AllPlots.csv` 
* Click Open --> Next
* OpenRefine gives you a preview - a chance to show you it understood the file. 
   * did the file show up sensibly? 
* in the upper right corner create a meaninful project name and then click "Create Project"

## Faceting

OpenRefine supports faceted browsing. This allows you tosee the big picture of your data and
then filter down to a subset of rows. Once you have a target set of rows, you can apply changes in bulk.

* lets work with one of the columns containing plant height measurements
  * next to one of the numeric columns (Plant_ht_Aug24) click the arrow
  * facet --> Numeric facet.
    * what went wrong?
  * click 'edit cells' --> common transforms --> numeric
  * now try to click facet --> numeric again
    * what do you see this time? 
    * How is a numeric facet different than a text facet?
  * click Plant_ht_Sep15
    * how many rows are there with non-numeric data?
    * what to do here?
    
Lets look at the Genotype field

* select the arrow next to the column named "Genotype"
* select "Facet" --> "Text Facet"
* sort by "count"
  * what do you notice? 
  * What is the level of replication in this study? 
  * Which genotypes are not like the others?
  * why are there so many Genotypes named "Great Scott" and "border"?
* Lets clean up all whitespace problems
  * trim leading and trailing whitespace
  * trim consecutive white space
  * now how many groups do we have?
* Edit "border" --> "Border"

### TERRA REF Sites and Variables
  
Your turn:

Lets review a few datasets from the TERRA REF trait database. These are provided in the .json format by default:

1. Look at the sites table. Where are the sites? Are there redundant names?
   * import from https://terraref.ncsa.illinois.edu/bety/api/beta/sites?key=9999999999999999999999999999999999999999&limit=none
   * when you review the data, select the lowest level of hierarchy so column names aren't long concatenations of the entire tree. 
2. See if you can find any redundant variables    
  * import from https://terraref.ncsa.illinois.edu/bety/api/beta/variables.xml?key=9999999999999999999999999999999999999999&limit=none
  * note that this is an XML format (the BETYdb API provide json, xml, and csv)


# Relational Databases and SQL


## Relational Databases


### Data Normalization

"Codd's Normal Forms" from (Codd 1970)  

> process of organizing the columns (attributes) and tables (relations) of a relational database to reduce data redundancy and improve data integrity. [Wikipedia - Database normalization](https://en.wikipedia.org/wiki/Database_normalization)

To motivate the use of a relational databases, lets start by looking at a table. 

#### Importing data from the web


##### Open Refine

* Lets look at the Miscanthus Yield dataset again
* Open --> Create Project --> From URL
  * Enter https://www.betydb.org/search.csv?search=Ayield
* What is the matter here? Lets clean up the imported dataset.
  * columns are csv
  * discard first 8 lines, parse next 1 line as column headers
  * also, 'parse cells to numbers, dates, etc'
* Create Project

##### From a Web Interface

Go to [betydb.org](https://betydb.org) and enter "Miscanthus Yield" into the search box and click the search glass icon.

Lets review the information in this table.

* Site with city
* Date + time + timezone
* Species + common name 
* Cultivar
* Trait 
* Mean (with units)
* Method
* Entity

Now click the "Download Results" button. This will download a .csv file. A .csv file is a table where each column is defined by a comma, e.g. a 3x3 matrix would be formatted thus:

```
row 1 col 1, row 1 col 2, row 1 col 3
row 2 col 1, row 2 col 2, row 2 col 3
row 3 col 1, row 3 col 2, row 3 col 3
```

_a brief note about csv files_

By default, many computers will open the csv file directly into a [spreadsheet program](https://en.wikipedia.org/wiki/spreadsheet) like Microsoft Excel or OpenOffice Calc. But because it is a text file, you can also open it in a [text editor](https://en.wikipedia.org/wiki/Text_editor) like Notepad, nano, or emacs.

It can also be easily read by any software or parsed at the command line using tools like `cut` and `sed`. Unlike xml and json, it is more intuitive for a human to read.

> where are redundancies?


## Lets look at the underlying database

Open the PostgreSQL application in the NDSLabs workbench.

```
Host: terra-bety.default
Port: 5432
User: bety
Password: bety
DB: bety
```

### Tables & Schemas


![A simplified entity–relationship diagram for key tables in Biofuel Ecophysiological Traits and Yields database (BETYdb).](http://onlinelibrary.wiley.com/store/10.1111/gcbb.12420/asset/image_n/gcbb12420-fig-0001.png?v=1&t=j2uxcy2q&s=ddb49c4e35c662b8ca120fc2882a17f28f0f50b5)

### Schemas



# SQL

Lets start using some basic SQL Commands

### Basic commands

SELECT
WHERE
JOIN

LIMIT
ORDER BY
GROUP BY
AND
OR
MIN
MAX
AVG
SUM
COUNT
LIKE


### Types of Joins

## Database Management Systems

### Common software

MySQL, PostgreSQL, Oracle, 

Access??

### Connecting to a database server

connection parameters
host
login
user
database

.pgpass

psql -U bety -d bety -h localhost

### R: RPostgreSQL and dplyr



### APIs

keys
### restful interface

get put delete 

### json data structures

### R traits package

## Real World Examples

### A Simple database

* Download data from BETYdb
* Discuss how to normalize it

### Advanced: BETYdb

* Full Schema betydb.org/schemas
* How would you query all of the planting dates associated with a trait record?

## Real World Application: the Biofuel Ecophysiological Traits and Yields database

![Summary BETYdb schema](https://pecan.gitbooks.io/betydb-data-access/content/betydb_schema.png)

We have created 'views' to make it easier to query data from multiple tables. For example, to lookup the name and location of a site or the names and units of variables. The following query joins multiple tables, and is based on the yieldsview table:

```sql
SELECT 'yields'::character(10) AS result_type,
    yields.id,
    yields.citation_id,
    yields.site_id,
    yields.treatment_id,
    sites.sitename,
    sites.city,
    st_y(st_centroid(sites.geometry)) AS lat,
    st_x(st_centroid(sites.geometry)) AS lon,
    species.scientificname,
    species.commonname,
    species.genus,
    species.id AS species_id,
    yields.cultivar_id,
    citations.author,
    citations.year AS citation_year,
    treatments.name AS treatment,
    yields.date,
    date_part('month'::text, yields.date) AS month,
    date_part('year'::text, yields.date) AS year,
    variables.name AS trait,
    variables.description AS trait_description,
    yields.mean,
    variables.units,
    yields.n,
    yields.statname,
    yields.stat,
    yields.notes,
   FROM ((((((yields
     LEFT JOIN sites ON ((yields.site_id = sites.id)))
     LEFT JOIN species ON ((yields.specie_id = species.id)))
     LEFT JOIN citations ON ((yields.citation_id = citations.id)))
     LEFT JOIN treatments ON ((yields.treatment_id = treatments.id)))
     LEFT JOIN variables ON (((variables.name)::text = 'Ayield'::text)))
     LEFT JOIN users ON ((yields.user_id = users.id)));
     
```

For more information, see the [BETYdb data access documentation](https://pecan.gitbooks.io/betydb-data-access/content/sqlqueries.html)

## references and further reading

* https://www.dataquest.io/blog/sql-basics/
* Codd, E.F. (June 1970). "A Relational Model of Data for Large Shared Data Banks". Communications of the ACM. 13 (6): 377–387. doi:10.1145/362384.362685.