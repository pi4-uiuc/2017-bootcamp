<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PI4 Computational Bootcamp</title>
    <link>/</link>
    <description>Recent content on PI4 Computational Bootcamp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jun 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bayesian Analysis</title>
      <link>/2017/06/06/bayesian-analysis/</link>
      <pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/06/bayesian-analysis/</guid>
      <description>Bayesian regression library(rstanarm) options(mc.cores = parallel::detectCores()) glm1 &amp;lt;- stan_glmer(yield_annual ~ fertilizer_n + age + genus:fertilizer_n + genus:age + (1 | site ), #prior = normal(30, 4), data = grass_yields) glm1 plot(glm1) plot(glm1, plotfun = &amp;#39;hist&amp;#39;) pairs(glm1) posterior_interval(glm1) summary(glm1) library(sjPlot) sjPlot::sjp.lmer(glm1) http://topepo.github.io/caret/train-models-by-tag.html https://thinkinator.com/2016/01/12/r-users-will-now-inevitably-become-bayesians/
 </description>
    </item>
    
    <item>
      <title>Stochastic Simulation</title>
      <link>/2017/06/06/stochastic-simulation/</link>
      <pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/06/stochastic-simulation/</guid>
      <description>Note: Some of the commands below, particularly those accessing the terraref database from within RStudio, require being logged into the NDS Analytics Workbench. This requires signing up for the TERRA REF Alpha User program
 library(ggplot2) Stochastic Simulation (Bolker Ch5) A deterministic linear function:
\[y_\rm{det}=a+bx\]
Add normally distributed errors, modeling \(\epsilon\sim(N(0,\sigma))\)
\[Y\sim N(a+bx, \sigma)\] Or equivalently:
\[Y\sim N(\mu, \sigma)\]
\[\mu = a+bx\] Lets first plot the deterministic function as a line</description>
    </item>
    
    <item>
      <title>Probability</title>
      <link>/2017/06/04/probability/</link>
      <pubDate>Sun, 04 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/04/probability/</guid>
      <description>Probability Distributions in R Objectives:  Become familiar with common probability distributions in R Understand how probability distributions are related to each other  Summarizing Data Expectation
If the random variable \(x\) can take values \(x_1,...,x_N\) with equal probability, the expected value \(E[x]\) of \(x\) is defined to be:
\[E[x]=\sum_{i=1}^N\frac{x_i}{N}\] Properties of the expected value: * \(E[x+y]=E[x]+E[y]\) * \(E[cx]=cE[x]\)
Variance
The variance of the random variable \(x\) is defined to be:</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/projects/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/projects/</guid>
      <description>Objectives Students should experience a collaborative development cycle similar to what they might encounter as a research programmer / software engineer / data scientist etc.
They will have the opportunity to contribute to open source projects (e.g. TERRA REF and PEcAn Projects). Their GitHub repositories, reports, and code will become part of their portfolio.
Projects will provide the opportunity for students to apply what we have learned in class to new datasets and analyses.</description>
    </item>
    
    <item>
      <title>Accessing Sensor Data 2</title>
      <link>/2017/05/31/accessing-sensor-data/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/31/accessing-sensor-data/</guid>
      <description>Hyperspectral Data Calibration Targets These were collected on April 15 2017 every ~15 minutes
library(ncdf4) library(dplyr) hsi_calibration_dir &amp;lt;- &amp;#39;/data/terraref/sites/ua-mac/Level_1/hyperspectral/2017-04-15&amp;#39; hsi_calibration_files &amp;lt;- dir(hsi_calibration_dir, recursive = TRUE, full.names = TRUE) fileinfo &amp;lt;- bind_rows(lapply(hsi_calibration_files, file.info)) %&amp;gt;% mutate(size_gb = size/1073741824) calibration_nc &amp;lt;- nc_open(hsi_calibration_files[200]) a &amp;lt;- calibration_nc$var$rfl_img #calibration_nc$dim$x$len 1600 #calibration_nc$dim$y$len x_length &amp;lt;- round(calibration_nc$dim$x$len / 10) y_length &amp;lt;- round(calibration_nc$dim$y$len * 3/4) xstart &amp;lt;- ceiling(calibration_nc$dim$x$len / 2) - floor(x_length / 2) + 1 ystart &amp;lt;- ceiling(calibration_nc$dim$y$len / 2) - floor(y_length / 2) + 1 rfl &amp;lt;- ncvar_get(calibration_nc, &amp;#39;rfl_img&amp;#39;, #start = c(1, xstart, ystart), #count = c(955, x_length, y_length) start = c(2, 2, 2), count = c(1320, 10, 954) ) x &amp;lt;- ncvar_get(calibration_nc, &amp;#39;x&amp;#39;, start = 100, count = 160) y &amp;lt;- ncvar_get(calibration_nc, &amp;#39;y&amp;#39;, start = 100, count = 1324) lambda &amp;lt;- calibration_nc$dim$wavelength$vals for(i in 1 + 0:10*95){ image(x = x, y = y, z = rfl[i,,], xlab = &amp;#39;x (m)&amp;#39;, ylab = &amp;#39;y (m)&amp;#39;, col = rainbow(n=100), main = paste(&amp;#39;wavelength&amp;#39;, udunits2::ud.</description>
    </item>
    
    <item>
      <title>Exploratory Data Analysis</title>
      <link>/2017/05/31/exploratory-data-analysis/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/31/exploratory-data-analysis/</guid>
      <description>Note: Some of the commands below, particularly those accessing the terraref database from within RStudio, require being logged into the NDS Analytics Workbench. This requires signing up for the TERRA REF Alpha User program.
 Objectives  Learning how to access data on terraref database via PostgreSQL
 Learning how to manipulate dat using the dplyr library, in particular: filtering, subsetting, summarizing, new variables with dplyr converting data from wide to long with tidyr</description>
    </item>
    
    <item>
      <title>3. Best Practices and Collaborative Development</title>
      <link>/2017/05/30/scrum-and-best-practices/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/30/scrum-and-best-practices/</guid>
      <description>Objectives:  Understand best practices by Wilson et al Basic components of Reproducible Research Be familiar with concepts related to Scrum   Best Practices in Scientific Computing Wilson et al 2014 Best practices in Scientific Computing Wilson et al paper: http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745
Slideshow: http://swcarpentry.github.io/slideshows/best-practices/
 Wilson et al 2017 Good enough practices in Scientific Computing Wilson et al paper: https://swcarpentry.github.io/good-enough-practices-in-scientific-computing/
 Example: PEcAn Project Please start the day by reading this.</description>
    </item>
    
    <item>
      <title>Databases and SQL</title>
      <link>/2017/05/30/databases-and-sql/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/30/databases-and-sql/</guid>
      <description>Overview We started with an overview of data management, including the data lifecycle, metadata, and databases, using the TERRA REF to illustrate applications.
  Spreadsheets and Tables A database is a generic term for data. Often these are divided into ‘relational’ and ‘non-relational’… We will get to these later. First, lets start with Spreadsheets, which are a simple, and very common format for data.
In fact, so far we have been working with tables.</description>
    </item>
    
    <item>
      <title>3. Introduction to R</title>
      <link>/2017/05/27/intro-to-r/</link>
      <pubDate>Sat, 27 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/27/intro-to-r/</guid>
      <description>This lesson is based on Getting Started with R and Rstudio (SWC 1-3).
Getting started with R Why R? * by design “a programming language and environment for statistical computing” * Most common language used by academic statisticians. Thus, many methods are developed as R packages and not available elsewhere. * built around stats, with lots of handy functions * data analysis by design * formulas for statistical models * ggplot ‘grammar of graphics’ among best graphing programs (only get better w/ graphical design programs like photoshop/Inkscape) * dplyr and tidyr for data munging * Integrates with lower level languages (esp C, C++, FORTRAN; Rcpp package for integration w/ C++ excellent) * can do anything * has a reputation for being slow.</description>
    </item>
    
    <item>
      <title>1. The Terminal (Unix Shell)</title>
      <link>/2017/05/26/the-terminal-unix-shell/</link>
      <pubDate>Fri, 26 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/26/the-terminal-unix-shell/</guid>
      <description>“What is a command shell and why would I use one?”
This tutorial is based on the Software Carpentry Unix Shell) [@swc_unix_shell] lesson, and will refer to it for background information.
Today we will learn - how the shell relates to the keyboard, the screen, the operating system, and users’ programs.&amp;quot; - when and why command-line interfaces should be used instead of graphical interfaces. - similarities and differences between a file and a directory.</description>
    </item>
    
    <item>
      <title>2. Version Control and Collaborative development</title>
      <link>/2017/05/26/version-control-git-github/</link>
      <pubDate>Fri, 26 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/26/version-control-git-github/</guid>
      <description>Version control makes it possible to have ‘unlimited undo’ and histories of your documents (and some smaller datasets)
Having everything on a website like GitHub (or Bitbucket or GitLab) makes it easy to share with other people and collaborate.
If you keep all of your important programs and files somewhere in the cloud, like on box.com, dropbox, github, it makes it easier to use heterogeneous environments.
Version Control SWC Git Novice 1-6 Getting Started Introduce yourself (once you’ve set this on your machine, you don’t have to set it again unless you want to change something):</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>This site includes material for the 2017 PI4 Computational Bootcamp taught to students in the Department of Mathematics, University of Illinois at Urbana-Champaign.</description>
    </item>
    
    <item>
      <title>Reading</title>
      <link>/reading/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/reading/</guid>
      <description>Day 1. Programming Fundamentals  Wilson et al 2014 Best Practices for Scientific Computing Agile Manifesto Vincent Dresen &amp;ldquo;A successful Git branching model&amp;rdquo;  Day 2: Getting started with R  Introduction, Data Structures, Subsetting, Functions in &amp;ldquo;Advanced R&amp;rdquo; by Wickham &amp;ldquo;Git and GitHub&amp;rdquo; in &amp;ldquo;R packages&amp;rdquo; by Wickham.  Day 3: Databases and Visualization  LeBauer, David, et al. &amp;ldquo;BETYdb: a yield, trait, and ecosystem service database applied to second‐generation bioenergy feedstock production.</description>
    </item>
    
    <item>
      <title>Syllabus</title>
      <link>/syllabus/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/syllabus/</guid>
      <description>Instructors: David LeBauer
 Carl R Woese Institute for Genomic Biology and National Center for Supercomputing Applications, University of Illinois email:dlebauer@illinois.edu  Neal Davis
 Department of Computer Science, University of Illinois email:davis68@illinois.edu  Stefan Klajbor (TA)
 Department of Mathematics, University of Illinois email:klajbor2@illinois.edu  Course Objectives A two week course designed to introduce Math graduate students with little or no programming experience to methods in data analysis and computation.</description>
    </item>
    
    <item>
      <title>Intro Statistics</title>
      <link>/2016/06/05/intro-statistics/</link>
      <pubDate>Sun, 05 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/06/05/intro-statistics/</guid>
      <description>Summary statistics Objectives: * learn to summarize data with basic measures of central tendancy and spread * learn to fit parametric distributions to data
Data analysis: Sorghum height data knitr::opts_chunk$set(cache = TRUE) library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union library(ggplot2) theme_set(theme_bw()) #bety_src &amp;lt;- RPostgreSQL::dbConnect(odbc::odbc(), &amp;quot;TERRA-REF traits copy BETYdb&amp;quot;) #bety_src &amp;lt;- src_postgres(dbname = &amp;quot;bety&amp;quot;, password = &amp;#39;bety&amp;#39;, host = &amp;#39;bety.</description>
    </item>
    
  </channel>
</rss>