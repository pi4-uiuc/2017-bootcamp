---
title: "4. Introduction to R"
author: "David LeBauer"
date: '2017-05-27'
tags: r
slug: intro-to-r
---


This lesson is based on [Getting Started with R and Rstudio (SWC 1-3)](http://swcarpentry.github.io/r-novice-gapminder/01-rstudio-intro/). 

Objectives: 

* Understand the utility of R as a language for data analysis 
* To gain familiarity with the Rstudio IDE: panes, buttons, shortcuts, options
* Where to get help in R.
* Learn to manage your workspace in an interactive R session
* Learn to find, install, and use packages / functions
* Load data
* call functions 
* Intro to reproducible research w/ R markdown

## Getting started with R

Why R?
* by design "a programming language and environment for statistical computing"
* Most common language used by academic statisticians. Thus, many methods are developed as R packages and not available elsewhere.
  * built around stats, with lots of handy functions
* data analysis by design
  * formulas for statistical models e.g. `yield ~ genotype + nitrogen + irrigation` 
  * vectorization, eg. `a <- 4 * X` instead of `for i in `1:length(X) a[i] <- 4 * X[i]`
  * ggplot 'grammar of graphics' among best graphing programs (only get better w/ graphical design programs like  photoshop/Inkscape)
  * dplyr and tidyr for data munging
* Integrates with lower level languages (esp C, C++, FORTRAN; Rcpp package for integration w/ C++ excellent)
* can do anything 

Why not R?

* different than many programming languages
* not good as a "first language" if you plan to use lower level languages in the future
* has a reputation for being slow. 
  * It can't be as fast as a compiled language (like C / FORTRAN)
  * Recent changes and new packages make it faster and better at handling big data (e.g. by leveraging back-end databases).


## Intro to Rstudio

Rstudio is the best IDE for programming in R. Developed by the [Rstudio](https://www.rstudio.com/) company, which leads the R community as a whole. Many leading R developers including Hadley Wickham (lead author of tidyverse, dplyr, ggplot2) and Yihui Xie (Rmarkdown, Shiny) work there. Now there are lots of 'plugins' that facilitate developing in R. 

If you love emacs, try the emacs-ess package. Especially if you are mostly writing scripts. It is really quite awesome. However, it doesn't compare to Rstudio once you start developing packages and writing reports or websites.

There are four panes (CCW from top left):

* text editor
* interactive environment
* files/plots/packages/help/viewer
* environment/history/build/git
  * environment: summaries of objects (e.g. data, variables, functions) 
  * history to source / console
  * git (we will use this alot). Often have to use command line

Handy buttons

* tools 
  * global options
  * shell
* Addins
* rerun on save

During this lesson I created the repository https://github.com/pi4-uiuc/day2, generated the file [`src/download_data_betydb.R]( https://github.com/pi4-uiuc/day2/blob/master/src/download_data_betydb.R), and populated the `data/` directory.


### Installing packages

```r
install.packages("tidyverse")
devtools::install_packages("terraref/traits")
devtools::install_packages("daattali/addinslist")
```

## R packages

* CRAN
* lots of packages on GitHub 
  * can get dev. versions
  * some packages not released through CRAN
* finding packages
  * CRAN Task Views , CRAN task views https://cran.r-project.org/web/views/
  * [Rdocumentation.org](https://www.rdocumentation.org/)


## Learning more about R and Getting Help

Hadley Wickham's books

* [R for Data Science](http://r4ds.had.co.nz/)
* [Advanced R](http://adv-r.had.co.nz/)
* [R Packages](http://r-pkgs.had.co.nz/)

The following provide real-world examples and announcements of new packages / releases / features.

* [R bloggers](https://www.r-bloggers.com/)
* [Journal of Statistical Software](https://www.jstatsoft.org/index)
* [R Journal](https://journal.r-project.org/)
* [Stackoverflow](https://stackoverflow.com/questions/tagged/r) and [Cross Validated](https://crossvalidated.com/questions/tagged/r)

### handy help functions

```r
?function
vignette(package = 'dplyr')
help.search('bayesian')
```

### stackoverflow, crossvalidated Q&A sites

Google works well. For errors / warnings copy parts of the message text (excluding information like variable names, paths, filenames specific to your environment).

What about beyond Google?

Stackexchange family of Q&A sites are excellent. These will frequently show up in your Google searches. When you go there, answers are ranked and often the 'best' answer is selected by the question asker. When you ask questions, in many cases you will get an answer in a few hours or a day. 

I learned a lot from these sites - they were instrumental in my education as a computational scientist. I have learned by reading existing answers as well as by asking and answering questions. You can see some of these on [various stackexchange websites](https://stackexchange.com/users/68240/david-lebauer).

[This question](https://stats.stackexchange.com/questions/5543/for-which-distributions-are-the-parameterizations-in-bugs-and-r-different) turned into [a journal article](https://journal.r-project.org/archive/2013/RJ-2013-020/index.html). 

#### How to ask a question?

Minimal reproducible example. See on ["How to make a great R reproducible example?"](https://stackoverflow.com/a/5963610/199217).

Contents:

* a **minimal dataset**, necessary to reproduce the error or example
  * `dput` an existing data frame
  * generate a `testdf <- data.frame(x = rnorm(100), y = rep(letters[1:4],25))`
* **minimal runnable code** necessary to reproduce the error / example, which can be run on the example dataset.
* **necessary information** on the used packages, R version and system it is run on.
   * R version, OS, packages
   * sometimes the comprehensive information in `sessionInfo()` or `devtools::session_info()` will help
* for random processes `set.seed()` for reproducibility
* the text of any errors

## Project organization

* Put each project in its own directory, which is named after the project.
* Put text documents associated with the project in the `/doc` directory.
* Put raw data and metadata in the `/data` directory, and files generated during cleanup and analysis in a results directory.
* Put source for the projectâ€™s scripts and programs in the `/src` or `/scripts` directory
* programs brought in from elsewhere or compiled locally in the `/bin` directory.
* Name all files to reflect their content or function.

From [Wilson et al "Good Enough Practices for Scientific Computing"](https://github.com/swcarpentry/good-enough-practices-in-scientific-computing/blob/gh-pages/good-enough-practices-for-scientific-computing.pdf) arXiv:1609.00037

```{r create_dirs, warning = FALSE, eval=FALSE}
lapply(c('doc', 'src', 'reports', 'data', 'results'),
       dir.create)
```

Here is one that I recently published: https://github.com/ebimodeling/betydb_manuscript

### Using the R packaging system framework

Once you start using functions, the R packaging system and its associated functions provide a good framework for R projects.

Lets look at one that I am currently working on: https://github.com/ebimodeling/willow_da

## Loading and Evaluating Data

Lets start by downloading the same data that we had last week:

* file --> import dataset --> from csv
  * source
  http://www.betydb.org/search.csv?search=Salix
  * comment symbol = `#`, skip = `2`, name = `salix`

It is great that the import is rendered as reproducible / reuseable R code, so this can be added to your script:

```{r import-salix, message = FALSE}
library(readr)
salix <- read_csv("http://www.betydb.org/search.csv?search=Salix", 
    comment = "#", skip = 2)
```

We also want to save a copy of this to our `/data` folder

```{r save-salix}
write_csv(salix, path = 'data/salix.csv')
```



## Control Flow (if, else, for) 

Here is how you write a 'for' loop in R:

```{r for-download-csv}
for(i in 1:10){
  print(paste('I am on iteration', i))
}
```
_your turn_

> import Poplar (_Populus_ spp), Miscanthus, and Switchgrass (_Panicum_ spp) data and save these as csv files


hint: `paste0("http://www.betydb.org/search.csv?search=", genus)`

```{r saveall, echo = FALSE, message = FALSE}
dir.create('data', showWarnings = FALSE, recursive = TRUE)
genera <- c('salix', 'populus', 'miscanthus', 'panicum')
for(genus in genera){
  # read in
  tmp <- read_csv(
    paste0("http://www.betydb.org/search.csv?search=", genus), 
    comment = "#", skip = 2)
  file <- file.path('data',paste0(genus, '.csv'))
  write_csv(tmp, path = file)
  # why use file.path instead of paste0?
  # hint: see description of ?file.path
}
```


### if, else


```{r if-else}
a <- 1:10
for(i in 1:10){
  if(a[i] %% 2 > 0){
    print(paste('element', i, 'is', a[i], 'which is even'))
  } else {
    print(paste('element', i, 'is', a[i], 'which is odd'))
  }
}

```

When you can vectorize ifelse:

```{r ifelse2}
ifelse(a %% 2 > 0, 
       'even', 
       'odd')
       
```


lets load up all of the csv files we just downloaded into a list of datasets:

```{r if-else-start}
multi_spp_list <- list()
```

```{r data-dont-exist-error, eval = FALSE, message = FALSE}
for(genus in  c('salix', 'miscanthus', 'acer')){ # for item(sing) in items(plural) ... 
  multi_spp_list[[genus]] <- read_csv(file.path('data', 
                                                paste0(genus, '.csv')))
} ## should break because acer.csv does not exist
```

```{r ifelse3, warnings=FALSE, eval = FALSE, message = FALSE}
for(genus in genera){ # for item(sing) in items(plural) ... 
  file <- file.path('data', paste0(genus, '.csv'))
  if(file.exists(file)){
    multi_spp_list[[genus]] <- read_csv(file)
  } else {
    warning(paste('file', file, 'does not exist'))
  }

} ## should break because acer.csv does not exist

```

This is where it is handy to recall that we previously defined the vector 'genera' and use it. 


### Vectorization


```{r vectors}
a <- c(1, 2, 2, 3)
b <- c(1, 2, 3, 4)

a^2 + b^2
```

```{r more-vectors}
c <- sqrt(a^2 + b^2)

abc <- matrix(c(a, b, c), ncol = 3)
abc^2
```


Element-wise vs. matrix multiplication

```{r elements-matrix-x}
# element-wise
a * a + b * b 
abc * abc

# matrix multiplication:
a %*% a + b %*% b 

# abc %*% abc # error ... not allowed

```

```{r vectorization}
sapply(1:10, function(x)  x>2)
```

```{r files-with-dir, message = FALSE}
# files <- dir("data", pattern = '.csv', full.names = TRUE)
files <- sapply(genera, function(x) paste0('data/', x, '.csv'))

multi_spp_list <- lapply(files, function(x) read_csv(x))
```


```{r vector-logical}

salix <- multi_spp_list$salix
salix$trait == 'Ayield'         ## becomes a logical vector
salix_yield <- salix[salix$trait == 'Ayield',] ## can be used for subsetting

## what fraction of salix yields are > 10?
salix_yield <- salix[salix$trait == 'Ayield',] ## can be used for subsetting

mean(salix_yield$mean > 10, na.rm = TRUE)
```

```{r lapply-examples}
lapply(multi_spp_list, class)
lapply(multi_spp_list, function(x) class(x$mean))

multi_spp_list2 <- lapply(multi_spp_list, 
                          function(x){
                            dplyr::mutate(x, mean = as.numeric(mean))
                          } )
multi_spp_df <- dplyr::bind_rows(multi_spp_list2)


## check that all rows made it 
lapply(multi_spp_list, nrow)
sum(unlist(lapply(multi_spp_list, nrow)))
nrow(multi_spp_df)

```


> your turn: write the above lapply statement as a for loop

Save the dataframe in results folder

```{r save-results}
write_csv(multi_spp_df, path = 'results/multi_spp_df.csv')
```

## Writing reports with R markdown

http://swcarpentry.github.io/r-novice-gapminder/15-knitr-markdown/


Support for many languages (Python, SQL, bash) http://rmarkdown.rstudio.com/authoring_knitr_engines.html#overview

Examples from class are in https://github.com/pi4-uiuc/day2/blob/master/exploratory-data-analysis.Rmd