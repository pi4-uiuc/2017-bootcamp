---
title: "5. Databases and SQL"
author: "David LeBauer"
date: '2017-05-30'
slug: databases-and-sql
tags: [r]
---


## Introduction 

<iframe src="https://docs.google.com/presentation/d/1dQHlodU9PggM7khqlL_OS4P-X-o96D78ihuvuD2Iong/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="749" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

## Spreadsheets and Tables

A database is a generic term for data. Often these are divided into 'relational' and 'non-relational'... We will get to these later. First, lets start with Spreadsheets, which are a simple, and very common format for data.

In fact, so far we have been working with tables.

## Miscanthus Yields

https://docs.google.com/spreadsheets/d/1MNG5BH6oDaRH4Ii1ZO7tVRV7pTZRKPv81In1NFdLFbs/edit#gid=0

## Sorghum Data from Arizona

Lets start with a spreadsheet that was prepared by a colleague of mine, Maria Newcomb, in Arizona

https://docs.google.com/spreadsheets/d/1ESwAR2-BpQ2HfaCoSDCQaiBJVab_5sHawEltyYcLP8U/edit#gid=932079509

Let's review the pages

* README is good. They are well ahead of the curve on this!
* What additional information is here?
* Where is the data we want to look at?
* What information is redundant


* Download the table "PlantHeights_AllPlots" as CSV


## Data Cleaning 

* In this lesson, we will use Open Refine to find errors, sort, and clean our dataset. 
* Open the OpenRefine container in the NDSLabs workbench

### About Open Refine

This tutorial is based on the [Data Carpentry Open Refine for Ecology lesson](http://www.datacarpentry.org/OpenRefine-ecology-lesson/01-working-with-openrefine/), modified to use our datasets.

You can learn more about and download Open Refine at [openrefine.org](https://openrefine.org). 


### Importing Data into Open Refine

Once OpenRefine is launched in your browser, the left margin has options to Create Project, Open Project, or Import Project. Here we will create a new project:

* click 'Create Project'; 'Get data from This Computer' should be selected
   * what other ways can you get data into OpenRefine?
* Click Choose Files and select the file `DRAFT_Sorghum2_PlantHeights_AugustPlanting-training-sample - PlantHeights_AllPlots.csv` 
* Click Open --> Next
* OpenRefine gives you a preview - a chance to show you it understood the file. 
   * did the file show up sensibly? 
* in the upper right corner create a meaninful project name and then click "Create Project"

### Faceting

OpenRefine supports faceted browsing. This allows you tosee the big picture of your data and
then filter down to a subset of rows. Once you have a target set of rows, you can apply changes in bulk.

* lets work with one of the columns containing plant height measurements
  * next to one of the numeric columns (Plant_ht_Aug24) click the arrow
  * facet --> Numeric facet.
    * what went wrong?
  * click 'edit cells' --> common transforms --> numeric
  * now try to click facet --> numeric again
    * what do you see this time? 
    * How is a numeric facet different than a text facet?
  * click Plant_ht_Sep15
    * how many rows are there with non-numeric data?
    * what to do here?
    
Lets look at the Genotype field

* select the arrow next to the column named "Genotype"
* select "Facet" --> "Text Facet"
* sort by "count"
  * what do you notice? 
  * What is the level of replication in this study? 
  * Which genotypes are not like the others?
  * why are there so many Genotypes named "Great Scott" and "border"?
* Lets clean up all whitespace problems
  * trim leading and trailing whitespace
  * trim consecutive white space
  * now how many groups do we have?
* Edit "border" --> "Border"

### TERRA REF Sites and Variables
  
Your turn:

Lets review a few datasets from the TERRA REF trait database. These are provided in the .json format by default:

1. Look at the sites table. Where are the sites? Are there redundant names?
   * import from https://terraref.ncsa.illinois.edu/bety/api/beta/sites?key=9999999999999999999999999999999999999999&limit=none
   * when you review the data, select the lowest level of hierarchy so column names aren't long concatenations of the entire tree. 
2. See if you can find any redundant variables    
  * import from https://terraref.ncsa.illinois.edu/bety/api/beta/variables.xml?key=9999999999999999999999999999999999999999&limit=none
  * note that this is an XML format (the BETYdb API provide json, xml, and csv)



#### Open Refine

* Lets look at the Miscanthus Yield dataset again
* Open --> Create Project --> From URL
  * Enter https://www.betydb.org/search.csv?search=Ayield
* What is the matter here? Lets clean up the imported dataset.
  * columns are csv
  * discard first 8 lines, parse next 1 line as column headers
  * also, 'parse cells to numbers, dates, etc'
* Create Project

#### From a Web Interface

Go to [betydb.org](https://betydb.org) and enter "Miscanthus Yield" into the search box and click the search glass icon.

Lets review the information in this table.

* Site with city
* Date + time + timezone
* Species + common name 
* Cultivar
* Trait 
* Mean (with units)
* Method
* Entity

Now click the "Download Results" button. This will download a .csv file. A .csv file is a table where each column is defined by a comma, e.g. a 3x3 matrix would be formatted thus:

```
row 1 col 1, row 1 col 2, row 1 col 3
row 2 col 1, row 2 col 2, row 2 col 3
row 3 col 1, row 3 col 2, row 3 col 3
```

_a brief note about csv files_

By default, many computers will open the csv file directly into a [spreadsheet program](https://en.wikipedia.org/wiki/spreadsheet) like Microsoft Excel or OpenOffice Calc. But because it is a text file, you can also open it in a [text editor](https://en.wikipedia.org/wiki/Text_editor) like Notepad, nano, or emacs.

It can also be easily read by any software or parsed at the command line using tools like `cut` and `sed`. Unlike xml and json, it is more intuitive for a human to read.

> where are redundancies?


* Site + city + lat + lon
* Date + time + timezone
* genus + scientificname + common name 
* Cultivar
* Trait + units & description 
* Mean 
* Method
* Entity

### Tidy data


* Each variable forms a column.
* Each observation forms a row.
* Each type of observational unit forms a table.

From [tidyr vignette](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)

> YOUR TURN Is the Miscanthus dataset tidy? What would we need to do to make it tidy?

## Relational Databases and SQL

### Data Normalization

"Codd's Normal Forms" from (Codd 1970)  

> process of organizing the columns (attributes) and tables (relations) of a relational database to reduce data redundancy and improve data integrity. [Wikipedia - Database normalization](https://en.wikipedia.org/wiki/Database_normalization)

To motivate the use of a relational databases, lets start by looking at a table. Is there redundant information (that violates the )

> YOUR TURN: which of these fields has redundant data? how would you begin to normalize this data set?


### Lets look at the underlying database

#### Connecting to a database server

connection parameters:

* host
* login
* user 
* database (database name)

Lets connect to the terraref instance of betydb. Until now we have been accessing betydb.org. Now we will access (a copy of) the database behind terraref.ncsa.illinois.edu/bety

```
Host: terra-bety.default
Port: 5432
User: bety
Password: bety
DB: bety
```

From the command line:

```sh
psql -U bety -d bety -h terra-bety.default
```

The hidden .pgpass file:

```sh
echo "terra-bety.default:5432:bety:bety:bety" >> ~/.pgpass
chmod 0600 ~/.pgpass # why?
psql 
```

Open the PostgreSQL application in the NDSLabs workbench and enter the connection parameters above.

### Tables & Schemas


![A simplified entity–relationship diagram for key tables in Biofuel Ecophysiological Traits and Yields database (BETYdb).](http://onlinelibrary.wiley.com/store/10.1111/gcbb.12420/asset/image_n/gcbb12420-fig-0001.png?v=1&t=j2uxcy2q&s=ddb49c4e35c662b8ca120fc2882a17f28f0f50b5)


## SQL

Lets start using some basic SQL Commands

```sql
SELECT
WHERE
JOIN

LIMIT
ORDER BY
GROUP BY
AND
OR
MIN
MAX
AVG
SUM
COUNT
LIKE
```

```sql
select * from traits limit 10;
select * from traits where mean < 0;
```

* where is all of the useful information????


### Types of Joins

![types of joins](http://r4ds.had.co.nz/diagrams/join-venn.png)

From [Grolemund and Wickham "R for Data Science"](http://r4ds.had.co.nz/relational-data.html)

```sql
select * from traits left join variables 
   on traits.variable_id = variables.id
   where variables.name = 'NDVI'
```

## Database Management Systems

### Common software

MySQL, PostgreSQL, Oracle, 

Access


### R: RPostgreSQL and dplyr

```{r}

```

### APIs

* sign into terraref.ncsa.illinois.edu/bety
  * username: `pi4-student`
  * password: `ask-instructor` <!--pi4student!!-->
* locate your API key and copy it <!-- sSJzqPF77rRus9BGOZS4T76fzNhQ5Nk01tjcf1Bh-->

* see [terraref tutorials 01- betydb getting started](https://github.com/terraref/tutorials/blob/master/traits/00-BETYdb-getting-started.Rmd)

#### restful interface

get put delete 
https://en.wikipedia.org/wiki/Representational_state_transfer

#### json data structures


### R traits package

Example: query indoor data from terraref database using the R traits package:

https://github.com/terraref/tutorials/blob/master/traits/02-danforth-phenotyping-facility.Rmd

## Real World Examples

### Advanced: BETYdb

* Full Schema betydb.org/schemas
* How would you query all of the planting dates associated with a trait record?

## Real World Application: the Biofuel Ecophysiological Traits and Yields database

![Summary BETYdb schema](https://pecan.gitbooks.io/betydb-data-access/content/betydb_schema.png)

We have created 'views' to make it easier to query data from multiple tables. For example, to lookup the name and location of a site or the names and units of variables. The following query joins multiple tables, and is based on the yieldsview table:

```sql
SELECT 'yields'::character(10) AS result_type,
    yields.id,
    yields.citation_id,
    yields.site_id,
    yields.treatment_id,
    sites.sitename,
    sites.city,
    st_y(st_centroid(sites.geometry)) AS lat,
    st_x(st_centroid(sites.geometry)) AS lon,
    species.scientificname,
    species.commonname,
    species.genus,
    species.id AS species_id,
    yields.cultivar_id,
    citations.author,
    citations.year AS citation_year,
    treatments.name AS treatment,
    yields.date,
    date_part('month'::text, yields.date) AS month,
    date_part('year'::text, yields.date) AS year,
    variables.name AS trait,
    variables.description AS trait_description,
    yields.mean,
    variables.units,
    yields.n,
    yields.statname,
    yields.stat,
    yields.notes,
   FROM ((((((yields
     LEFT JOIN sites ON ((yields.site_id = sites.id)))
     LEFT JOIN species ON ((yields.specie_id = species.id)))
     LEFT JOIN citations ON ((yields.citation_id = citations.id)))
     LEFT JOIN treatments ON ((yields.treatment_id = treatments.id)))
     LEFT JOIN variables ON (((variables.name)::text = 'Ayield'::text)))
     LEFT JOIN users ON ((yields.user_id = users.id)));
     
```

For more information, see the [BETYdb data access documentation](https://pecan.gitbooks.io/betydb-data-access/content/sqlqueries.html)

## references and further reading

* https://www.dataquest.io/blog/sql-basics/
* Codd, E.F. (June 1970). "A Relational Model of Data for Large Shared Data Banks". Communications of the ACM. 13 (6): 377–387. doi:10.1145/362384.362685.